# data_standardization.py
# =============================================================================
# DATA STANDARDIZATION PIPELINE (ETL STEP 1)
# QUY TR√åNH CHU·∫®N H√ìA D·ªÆ LI·ªÜU
#
# Description:
# 1. Read raw JSON data / ƒê·ªçc d·ªØ li·ªáu th√¥ t·ª´ JSON.
# 2. Normalize Brand names / Chu·∫©n h√≥a t√™n th∆∞∆°ng hi·ªáu.
# 3. Extract technical specs using Regex / Tr√≠ch xu·∫•t th√¥ng s·ªë k·ªπ thu·∫≠t.
# 4. Handle data anomalies safely / X·ª≠ l√Ω an to√†n c√°c d·ªØ li·ªáu l·ªói.
#
# Author: AI Engineer
# Date: 2026
# =============================================================================

import json
import re
from pathlib import Path
from typing import Dict, Optional, Any

# =============================================================================
# 1. PATH CONFIGURATION (C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N)
# =============================================================================
ROOT = Path(__file__).resolve().parents[1]
DATA_DIR = ROOT / "data"

INPUT_FILE = DATA_DIR / "datalaptop.json"
OUTPUT_FILE = DATA_DIR / "products_final.jsonl"

# Ensure output directory exists / ƒê·∫£m b·∫£o th∆∞ m·ª•c t·ªìn t·∫°i
if not DATA_DIR.exists():
    DATA_DIR.mkdir(parents=True, exist_ok=True)

# =============================================================================
# 2. UTILITY FUNCTIONS (C√ÅC H√ÄM TI·ªÜN √çCH)
# =============================================================================
def norm(text: Optional[str]) -> str:
    """
    Normalize text: lower case and strip whitespace.
    Chu·∫©n h√≥a vƒÉn b·∫£n: chuy·ªÉn th∆∞·ªùng v√† x√≥a kho·∫£ng tr·∫Øng th·ª´a.
    """
    return text.lower().strip() if isinstance(text, str) else ""

def extract_int(pattern: str, text: str) -> Optional[int]:
    """
    Extract integer safely using Regex.
    Tr√≠ch xu·∫•t s·ªë nguy√™n an to√†n.
    """
    if not text: return None
    # Use IGNORECASE for robustness / D√πng c·ªù IGNORECASE ƒë·ªÉ b·∫Øt c·∫£ hoa/th∆∞·ªùng
    m = re.search(pattern, text, re.IGNORECASE)
    return int(m.group(1)) if m else None

def extract_float(pattern: str, text: str) -> Optional[float]:
    """
    Extract float safely using Regex.
    Tr√≠ch xu·∫•t s·ªë th·ª±c an to√†n (x·ª≠ l√Ω d·∫•u ph·∫©y).
    """
    if not text: return None
    text = text.replace(",", ".")
    m = re.search(pattern, text, re.IGNORECASE)
    return float(m.group(1)) if m else None

# =============================================================================
# 3. BRAND NORMALIZATION (CHU·∫®N H√ìA TH∆Ø∆†NG HI·ªÜU)
# =============================================================================
def normalize_brand(name: str) -> str:
    """
    Map various brand spellings to canonical names.
    √Ånh x·∫° c√°c c√°ch vi·∫øt t√™n h√£ng v·ªÅ t√™n chu·∫©n.
    """
    t = norm(name)
    
    if "gigabyte" in t or "giga" in t: return "Gigabyte"
    if "asus" in t: return "Asus"
    if "msi" in t: return "MSI"
    if "acer" in t: return "Acer"
    if "lenovo" in t: return "Lenovo"
    if "dell" in t: return "Dell"
    if "hp" in t: return "HP"
    if "macbook" in t or "apple" in t: return "Apple"
    if "lg" in t: return "LG"
    
    return "Other"

# =============================================================================
# 4. CORE STANDARDIZATION LOGIC (LOGIC CHU·∫®N H√ìA CH√çNH)
# =============================================================================
def standardize(item: Dict[str, Any], idx: int) -> Dict[str, Any]:
    """
    Process a single raw product item into a structured format.
    X·ª≠ l√Ω m·ªôt s·∫£n ph·∫©m th√¥ th√†nh ƒë·ªãnh d·∫°ng c·∫•u tr√∫c chu·∫©n.
    """
    # Fallback name if missing / T√™n m·∫∑c ƒë·ªãnh n·∫øu thi·∫øu
    name = item.get("T√™n s·∫£n ph·∫©m", f"Laptop {idx}")

    # 1. Price Parsing / X·ª≠ l√Ω gi√° ti·ªÅn
    # Handle 'Contact' or invalid prices gracefully
    try:
        price_str = str(item.get("Gi√°", 0))
        price = int(re.sub(r"[^\d]", "", price_str))
    except ValueError:
        price = 0

    # 2. Raw Specs / Th√¥ng s·ªë th√¥
    cpu = item.get("C√¥ng ngh·ªá CPU", "")
    gpu = item.get("Card m√†n h√¨nh", "")

    # 3. RAM Parsing / X·ª≠ l√Ω RAM
    # Captures: 16GB, 16 gb, 16Gb...
    ram_raw = norm(item.get("RAM", ""))
    ram = extract_int(r"(\d+)\s*gb", ram_raw) or 0

    # 4. Storage Parsing / X·ª≠ l√Ω ·ªï c·ª©ng
    # Fix regex group issue: use non-capturing group (?:...)
    # B·∫Øt s·ªë ƒë·ª©ng tr∆∞·ªõc GB ho·∫∑c TB
    ssd_raw = norm(item.get("·ªî c·ª©ng", ""))
    ssd = extract_int(r"(\d+)\s*(?:gb|tb)", ssd_raw) or 0
    
    # Convert TB to GB / ƒê·ªïi TB sang GB
    if "tb" in ssd_raw:
        ssd *= 1024

    # 5. Screen Size / K√≠ch th∆∞·ªõc m√†n h√¨nh
    screen = extract_float(r"(\d+(\.\d+)?)", item.get("K√≠ch th∆∞·ªõc m√†n h√¨nh", "")) or 0.0

    # 6. Refresh Rate / T·∫ßn s·ªë qu√©t
    hz_raw = norm(item.get("T·∫ßn s·ªë qu√©t", ""))
    hz = extract_int(r"(\d+)\s*hz", hz_raw)
    
    # Heuristic fallback: if no 'Hz' unit found, check for common values > 50
    if not hz:
        hz_fallback = extract_int(r"\b(\d{2,3})\b", hz_raw)
        hz = hz_fallback if hz_fallback and hz_fallback > 50 else 60

    # 7. Weight / Tr·ªçng l∆∞·ª£ng
    # Default to 0.0 to allow math operations later
    weight = extract_float(r"(\d+(\.\d+)?)\s*kg", norm(item.get("K√≠ch th∆∞·ªõc", ""))) or 0.0

    # 8. Brand / Th∆∞∆°ng hi·ªáu
    brand = normalize_brand(name)

    # Return structured dict / Tr·∫£ v·ªÅ dictionary ƒë√£ chu·∫©n h√≥a
    return {
        "id": idx,
        "name": name,
        "brand": brand,
        "price_value": price,
        "cpu": cpu,
        "gpu": gpu,
        "ram_gb": ram,
        "ssd_gb": ssd,
        "screen_size_inch": screen,
        "refresh_rate_hz": hz,
        "weight_kg": weight,
        "raw_source": item,  # Keep full raw data / Gi·ªØ l·∫°i to√†n b·ªô d·ªØ li·ªáu g·ªëc
    }

# =============================================================================
# 5. MAIN EXECUTION (CH∆Ø∆†NG TR√åNH CH√çNH)
# =============================================================================
def main():
    if not INPUT_FILE.exists():
        print(f"‚ùå Input file not found / Kh√¥ng t√¨m th·∫•y file: {INPUT_FILE}")
        return

    print(f"üìÇ Reading data from / ƒêang ƒë·ªçc d·ªØ li·ªáu t·ª´: {INPUT_FILE}")
    with open(INPUT_FILE, "r", encoding="utf-8") as f:
        data = json.load(f)

    print(f"üîÑ Standardizing {len(data)} products... / ƒêang chu·∫©n h√≥a...")
    
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        for i, item in enumerate(data, 1):
            std_item = standardize(item, i)
            # Write line by line (JSONL) / Ghi t·ª´ng d√≤ng format JSONL
            f.write(json.dumps(std_item, ensure_ascii=False) + "\n")

    print(f"‚úÖ Standardization complete! / Ho√†n t·∫•t chu·∫©n h√≥a!")
    print(f"üìÑ Output saved to / File l∆∞u t·∫°i: {OUTPUT_FILE}")

if __name__ == "__main__":
    main()